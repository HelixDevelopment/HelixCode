# HelixCode Server Configuration

server:
  address: "0.0.0.0"
  port: 8080
  read_timeout: 30
  write_timeout: 30
  idle_timeout: 60
  shutdown_timeout: 30

database:
  host: "localhost"
  port: 5432
  user: "helixcode"
  password: "" # Set via HELIX_DATABASE_PASSWORD environment variable
  dbname: "helixcode"
  sslmode: "disable"

redis:
  host: "localhost"
  port: 6379
  password: "" # Set via HELIX_REDIS_PASSWORD environment variable
  db: 0
  enabled: true

auth:
  jwt_secret: "" # Set via HELIX_AUTH_JWT_SECRET environment variable
  token_expiry: 86400
  session_expiry: 604800
  bcrypt_cost: 12

workers:
  health_check_interval: 30
  health_ttl: 120
  max_concurrent_tasks: 10

tasks:
  max_retries: 3
  checkpoint_interval: 300
  cleanup_interval: 3600

llm:
  default_provider: "local"
  providers:
    # Existing providers
    local:
      type: local
      endpoint: "http://localhost:11434"
    ollama:
      type: ollama
      endpoint: "http://localhost:11434"
    llamacpp:
      type: llamacpp
      endpoint: "http://localhost:8080"
    
    # New OpenAI-compatible providers
    vllm:
      type: vllm
      endpoint: "http://localhost:8000"
      models: ["llama-2-7b-chat-hf"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    localai:
      type: localai
      endpoint: "http://localhost:8080"
      models: ["gpt-3.5-turbo"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    fastchat:
      type: fastchat
      endpoint: "http://localhost:7860"
      models: ["vicuna-13b-v1.5"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    textgen:
      type: textgen
      endpoint: "http://localhost:5000"
      models: ["llama-2-7b-chat-hf"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    lmstudio:
      type: lmstudio
      endpoint: "http://localhost:1234"
      models: ["local-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    jan:
      type: jan
      endpoint: "http://localhost:1337"
      models: ["jan-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    gpt4all:
      type: gpt4all
      endpoint: "http://localhost:4891"
      models: ["gpt4all-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: false
    
    koboldai:
      type: koboldai
      endpoint: "http://localhost:5001"
      models: ["kobold-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    tabbyapi:
      type: tabbyapi
      endpoint: "http://localhost:5000"
      models: ["tabby-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    mlx:
      type: mlx
      endpoint: "http://localhost:8080"
      models: ["mlx-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    mistralrs:
      type: mistralrs
      endpoint: "http://localhost:8080"
      models: ["mistral-model"]
      enabled: false
      parameters:
        timeout: 30.0
        max_retries: 3
        streaming_support: true
    
    # Cloud providers (existing)
    openai: "" # Set API key via environment variable
    anthropic: "" # Set API key via environment variable
    gemini: "" # Set API key via environment variable
    vertexai: "" # Set credentials via environment variables
    qwen: "" # Set API key via environment variable
    xai: "" # Set API key via environment variable
    openrouter: "" # Set API key via environment variable
    copilot: "" # Set GitHub token via environment variable
    bedrock: "" # Set AWS credentials via environment variables
    azure: "" # Set Azure credentials via environment variables
    groq: "" # Set API key via environment variable
  
  max_tokens: 4096
  temperature: 0.7
  timeout: 30
  max_retries: 3
  
  # Provider selection preferences
  selection:
    strategy: "performance"  # performance, cost, availability, round-robin
    fallback_enabled: true
    health_check_interval: 30

logging:
  level: "info"
  format: "text"
  output: "stdout"

notifications:
  enabled: true

  # Notification rules - map events to channels
  rules:
    - name: "Critical Task Failures"
      condition: "type==error"
      channels: ["slack", "email", "telegram"]
      priority: urgent
      enabled: true

    - name: "Worker Health Alerts"
      condition: "type==alert"
      channels: ["slack", "telegram"]
      priority: high
      enabled: true

    - name: "Workflow Completions"
      condition: "type==success"
      channels: ["slack"]
      priority: medium
      enabled: true

  # Channel configurations
  channels:
    slack:
      enabled: false  # Set to true and configure webhook to enable
      webhook_url: ""  # Set via HELIX_SLACK_WEBHOOK_URL environment variable
      channel: "#helix-notifications"
      username: "HelixCode Bot"
      timeout: 10

    telegram:
      enabled: false  # Set to true and configure bot to enable
      bot_token: ""  # Set via HELIX_TELEGRAM_BOT_TOKEN environment variable
      chat_id: ""  # Set via HELIX_TELEGRAM_CHAT_ID environment variable
      timeout: 10

    email:
      enabled: false  # Set to true and configure SMTP to enable
      smtp:
        server: ""  # Set via HELIX_EMAIL_SMTP_SERVER
        port: 587  # Set via HELIX_EMAIL_SMTP_PORT
        username: ""  # Set via HELIX_EMAIL_USERNAME
        password: ""  # Set via HELIX_EMAIL_PASSWORD
        from: ""  # Set via HELIX_EMAIL_FROM
        tls: true
      recipients:
        default: []  # Set via HELIX_EMAIL_RECIPIENTS (comma-separated)
      timeout: 30

    discord:
      enabled: false  # Set to true and configure webhook to enable
      webhook_url: ""  # Set via HELIX_DISCORD_WEBHOOK_URL environment variable
      timeout: 10